{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e2fd5d-cd1f-49f5-8ad7-69ccb6f8bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train generated SVD & RNN4REC reco simulation test initialisation\n",
    "import tensorflow as tf\n",
    "\n",
    "from libreco.data import random_split, DatasetPure\n",
    "from libreco.algorithms import SVD, RNN4Rec\n",
    "from libreco.evaluation import evaluate\n",
    "\n",
    "from puzzling_models_utils import get_float_steps_between\n",
    "from puzzling_models_file_handling import load_char_from_csv_file, load_trainuser_testuser_trainchar_from_csv_file, save_one_metric_result_in_csv_file\n",
    "\n",
    "path = \"datasets/\"\n",
    "#dataset = \"movielens_25m\"\n",
    "dataset = \"yelp\"\n",
    "categories = False\n",
    "ids_wanted = '1'\n",
    "max_user = 1000\n",
    "min_rank_nb = 20\n",
    "show_lines = False\n",
    "timed = True\n",
    "\n",
    "resultpath = \"results/res_test.csv\"\n",
    "sims_wanted = [0,1]\n",
    "sim_step = .1\n",
    "\n",
    "# test & eval ratio with the same global % of the dataset\n",
    "test_ratio = 0.1\n",
    "train_eval_ratio = 1.0 - test_ratio\n",
    "eval_ratio = test_ratio / train_eval_ratio\n",
    "train_ratio = 1.0 - eval_ratio\n",
    "users_trainset = 100*train_eval_ratio\n",
    "\n",
    "print(f\"train [{train_ratio}] : {users_trainset*train_ratio}%, eval [{eval_ratio}] : {users_trainset*eval_ratio}%, test [{test_ratio}] : {100*test_ratio}%\")\n",
    "\n",
    "step_array = get_float_steps_between(sims_wanted[0], sims_wanted[1], sim_step)\n",
    "print(step_array)\n",
    "\n",
    "def reset_state():\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "ranking_metrics = [\"loss\", \"balanced_accuracy\", \"ndcg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac33620-20e9-4500-b583-650c928db59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train generated SVD reco simulation test with all sims\n",
    "recommenderAlg = \"SVD\"\n",
    "\n",
    "for sim_wanted in step_array:\n",
    "    user_rankings, char_train_data = load_char_from_csv_file(path, dataset, categories, sim_wanted, max_user=max_user, min_rank_nb=min_rank_nb, ids_set=ids_wanted)\n",
    "    user_train_data, user_test_data, char_train_data = load_trainuser_testuser_trainchar_from_csv_file(path, dataset, categories, sim_wanted, max_user=max_user, min_rank_nb=min_rank_nb, ids_set=ids_wanted, path_subfile='/chars_test/', path_index='datasets/char_index_test.csv')\n",
    "\n",
    "    train_data, eval_data, test_data = random_split(user_rankings, multi_ratios=[0.8, 0.1, 0.1])\n",
    "\n",
    "    train_user_data, data_user_info = DatasetPure.build_trainset(train_data)\n",
    "    eval_user_data = DatasetPure.build_evalset(eval_data)\n",
    "    test_user_data = DatasetPure.build_testset(test_data)\n",
    "\n",
    "    print(\"user -> user\")\n",
    "    reset_state()\n",
    "    svd_rank = SVD('ranking', data_info=data_user_info)\n",
    "    print(\"user - train\")\n",
    "    svd_rank.fit(\n",
    "        train_user_data,\n",
    "        verbose=0,\n",
    "        neg_sampling=True,\n",
    "        eval_data=eval_user_data,\n",
    "        metrics=ranking_metrics\n",
    "    )\n",
    "    print(\"user - eval\")\n",
    "    ranking_evaluations = evaluate(\n",
    "        model=svd_rank,\n",
    "        data=test_user_data,\n",
    "        neg_sampling=True,\n",
    "        metrics=ranking_metrics\n",
    "    )\n",
    "    print(\"user - save\")\n",
    "    save_one_metric_result_in_csv_file(resultpath, dataset, \"users\", ids_wanted, categories, sim_wanted, recommenderAlg, \"balancedAccuracy\", ranking_evaluations[\"balanced_accuracy\"])\n",
    "    save_one_metric_result_in_csv_file(resultpath, dataset, \"users\", ids_wanted, categories, sim_wanted, recommenderAlg, \"ndcg\", ranking_evaluations[\"ndcg\"])\n",
    "    save_one_metric_result_in_csv_file(resultpath, dataset, \"users\", ids_wanted, categories, sim_wanted, recommenderAlg, \"loss\", ranking_evaluations[\"loss\"])\n",
    "\n",
    "    print(\"char -> user\")\n",
    "    train_char_data, eval_char_data = random_split(char_train_data, multi_ratios=[train_ratio, eval_ratio])\n",
    "    train_char_data, data_char_info = DatasetPure.build_trainset(train_char_data)\n",
    "    eval_char_data = DatasetPure.build_evalset(eval_char_data)\n",
    "\n",
    "    test_user_data = DatasetPure.build_testset(user_test_data)\n",
    "\n",
    "    reset_state()\n",
    "\n",
    "    svdchar_rank = SVD('ranking', data_info=data_char_info)\n",
    "    print(\"char - train\")\n",
    "    svdchar_rank.fit(\n",
    "        train_char_data,\n",
    "        verbose=0,\n",
    "        neg_sampling=True,\n",
    "        eval_data=eval_char_data,\n",
    "        metrics=ranking_metrics\n",
    "    )\n",
    "    print(\"char - train\")\n",
    "    ranking_evaluationsChar = evaluate(\n",
    "        model=svdchar_rank,\n",
    "        data=test_user_data,\n",
    "        neg_sampling=True,\n",
    "        metrics=ranking_metrics\n",
    "    )\n",
    "    print(\"char - save\")\n",
    "    save_one_metric_result_in_csv_file(resultpath, dataset, \"chars\", ids_wanted, categories, sim_wanted, recommenderAlg, \"balancedAccuracy\", ranking_evaluationsChar[\"balanced_accuracy\"])\n",
    "    save_one_metric_result_in_csv_file(resultpath, dataset, \"chars\", ids_wanted, categories, sim_wanted, recommenderAlg, \"ndcg\", ranking_evaluationsChar[\"ndcg\"])\n",
    "    save_one_metric_result_in_csv_file(resultpath, dataset, \"chars\", ids_wanted, categories, sim_wanted, recommenderAlg, \"loss\", ranking_evaluationsChar[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34803bb4-3aab-42e4-b751-a3e81ae9a89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train generated RNN4Rec reco simulation with all sims\n",
    "recommenderAlg = \"RNN4Rec\"\n",
    "print(f\"{dataset} - {categories} idset[{ids_wanted}] reco {recommenderAlg}\");\n",
    "\n",
    "for sim_wanted in step_array:\n",
    "    user_rankings, char_train_data = load_char_from_csv_file(path, dataset, categories, sim_wanted, max_user=max_user, min_rank_nb=min_rank_nb, ids_set=ids_wanted)\n",
    "    user_train_data, user_test_data, char_train_data = load_trainuser_testuser_trainchar_from_csv_file(path, dataset, categories, sim_wanted, max_user=max_user, min_rank_nb=min_rank_nb, ids_set=ids_wanted, path_subfile='/chars_test/', path_index='datasets/char_index_test.csv')\n",
    "\n",
    "    train_data, eval_data, test_data = random_split(user_rankings, multi_ratios=[0.8, 0.1, 0.1])\n",
    "\n",
    "    train_user_data, data_user_info = DatasetPure.build_trainset(train_data)\n",
    "    eval_user_data = DatasetPure.build_evalset(eval_data)\n",
    "    test_user_data = DatasetPure.build_testset(test_data)\n",
    "\n",
    "    print(\"user -> user\")\n",
    "    reset_state()\n",
    "    rnn_rank = RNN4Rec(\n",
    "        \"ranking\",\n",
    "        data_user_info,\n",
    "        rnn_type=\"lstm\",\n",
    "        embed_size=16,\n",
    "        n_epochs=5,\n",
    "        lr=0.001,\n",
    "        lr_decay=False,\n",
    "        hidden_units=(16, 16),\n",
    "        reg=None,\n",
    "        batch_size=256,\n",
    "        num_neg=1,\n",
    "        dropout_rate=None,\n",
    "        recent_num=10,\n",
    "        tf_sess_config=None,\n",
    "    )\n",
    "    rnn_rank.fit(\n",
    "        train_user_data,\n",
    "        neg_sampling=True,\n",
    "        verbose=2,\n",
    "        shuffle=True,\n",
    "        eval_data=eval_user_data,\n",
    "        metrics=ranking_metrics,\n",
    "    )\n",
    "    ranking_evaluations = evaluate(\n",
    "        model=rnn_rank,\n",
    "        data=test_user_data,\n",
    "        neg_sampling=True,\n",
    "        metrics=ranking_metrics\n",
    "    )\n",
    "    \n",
    "    print(\"user - save\")\n",
    "\n",
    "    print(ranking_evaluations)\n",
    "    save_one_metric_result_in_csv_file(resultpath, dataset, \"users\", ids_wanted, categories, sim_wanted, recommenderAlg, \"balancedAccuracy\", ranking_evaluations[\"balanced_accuracy\"])\n",
    "    save_one_metric_result_in_csv_file(resultpath, dataset, \"users\", ids_wanted, categories, sim_wanted, recommenderAlg, \"ndcg\", ranking_evaluations[\"ndcg\"])\n",
    "    save_one_metric_result_in_csv_file(resultpath, dataset, \"users\", ids_wanted, categories, sim_wanted, recommenderAlg, \"loss\", ranking_evaluations[\"loss\"])\n",
    "\n",
    "    print(\"char -> user\")\n",
    "    train_char_data, eval_char_data = random_split(char_train_data, multi_ratios=[train_ratio, eval_ratio])\n",
    "    train_char_data, data_char_info = DatasetPure.build_trainset(train_char_data)\n",
    "    eval_char_data = DatasetPure.build_evalset(eval_char_data)\n",
    "\n",
    "    test_user_data = DatasetPure.build_testset(user_test_data)\n",
    "\n",
    "    reset_state()\n",
    "\n",
    "    rnn_rank = RNN4Rec(\n",
    "        \"ranking\",\n",
    "        data_char_info,\n",
    "        rnn_type=\"lstm\",\n",
    "        embed_size=16,\n",
    "        n_epochs=5,\n",
    "        lr=0.001,\n",
    "        lr_decay=False,\n",
    "        hidden_units=(16, 16),\n",
    "        reg=None,\n",
    "        batch_size=256,\n",
    "        num_neg=1,\n",
    "        dropout_rate=None,\n",
    "        recent_num=10,\n",
    "        tf_sess_config=None,\n",
    "    )\n",
    "    rnn_rank.fit(\n",
    "        train_char_data,\n",
    "        neg_sampling=True,\n",
    "        verbose=2,\n",
    "        shuffle=True,\n",
    "        eval_data=eval_char_data,\n",
    "        metrics=ranking_metrics,\n",
    "    )\n",
    "    ranking_evaluationsChar = evaluate(\n",
    "        model=rnn_rank,\n",
    "        data=test_user_data,\n",
    "        neg_sampling=True,\n",
    "        metrics=ranking_metrics\n",
    "    )\n",
    "    \n",
    "    print(\"char - save\")\n",
    "    print(ranking_evaluationsChar)\n",
    "    save_one_metric_result_in_csv_file(resultpath, dataset, \"chars\", ids_wanted, categories, sim_wanted, recommenderAlg, \"balancedAccuracy\", ranking_evaluationsChar[\"balanced_accuracy\"])\n",
    "    save_one_metric_result_in_csv_file(resultpath, dataset, \"chars\", ids_wanted, categories, sim_wanted, recommenderAlg, \"ndcg\", ranking_evaluationsChar[\"ndcg\"])\n",
    "    save_one_metric_result_in_csv_file(resultpath, dataset, \"chars\", ids_wanted, categories, sim_wanted, recommenderAlg, \"loss\", ranking_evaluationsChar[\"loss\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
